{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "There are three exercises in this notebook:\n",
    "\n",
    "1. Use the cross-validation method to test the linear regression with different $\\alpha$ values, at least three.\n",
    "2. Implement a SGD method that will train the Lasso regression for 10 epochs.\n",
    "3. Extend the Fisher's classifier to work with two features. Use the class as the $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cross-validation linear regression\n",
    "\n",
    "You need to change the variable ``alpha`` to be a list of alphas. Next do a loop and finally compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         1.61814247]] [-180.92401772]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>-20.590447</td>\n",
       "      <td>0.710486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>-101.723971</td>\n",
       "      <td>1.169788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>-167.855340</td>\n",
       "      <td>1.544160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>-179.526286</td>\n",
       "      <td>1.610230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>-180.783266</td>\n",
       "      <td>1.617346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 b         a\n",
       "1.0000  -20.590447  0.710486\n",
       "0.1000 -101.723971  1.169788\n",
       "0.0100 -167.855340  1.544160\n",
       "0.0010 -179.526286  1.610230\n",
       "0.0001 -180.783266  1.617346"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "x = np.array([188, 181, 197, 168, 167, 187, 178, 194, 140, 176, 168, 192, 173, 142, 176]).reshape(-1, 1).reshape(15,1)\n",
    "y = np.array([141, 106, 149, 59, 79, 136, 65, 136, 52, 87, 115, 140, 82, 69, 121]).reshape(-1, 1).reshape(15,1)\n",
    "\n",
    "x = np.asmatrix(np.c_[np.ones((15,1)),x])\n",
    "\n",
    "\n",
    "I = np.identity(2)\n",
    "alpha = [1,0.1,0.01,0.001,0.0001] # change here\n",
    "\n",
    "# add 1-3 line of code here\n",
    "results = []\n",
    "regr = linear_model.LinearRegression().fit(np.asarray(x),np.asarray(y))\n",
    "print(regr.coef_,regr.intercept_)\n",
    "\n",
    "for a in alpha:\n",
    "    w = np.linalg.inv(x.T*x + a * I)*x.T*y\n",
    "    w=w.ravel()\n",
    "    results.append(w)\n",
    "    \n",
    "results = np.asarray(results).flatten().reshape(5,2)\n",
    "dataframe = pd.DataFrame(data=results,index=alpha,columns=[\"b\",\"a\"])\n",
    "\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Implement based on the Ridge regression example, the Lasso regression.\n",
    "\n",
    "Please implement the SGD method and compare the results with the sklearn Lasso regression results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(x, y, n, epochs=1000):\n",
    "    x_mean, x_std = np.mean(x), np.std(x)\n",
    "    y_mean, y_std = np.mean(y), np.std(y)\n",
    "    x = (x - x_mean) / x_std\n",
    "    y = (y - y_mean) / y_std\n",
    "    w, b = 0.0, 0.0\n",
    "    \n",
    "\n",
    "    for _ in range(epochs):\n",
    "        indices = np.random.permutation(len(y))\n",
    "        for i in indices:\n",
    "            xi, yi = x[i], y[i]\n",
    "            y_pred = w * xi + b\n",
    "            error = y_pred - yi\n",
    "            \n",
    "            w -= n * error * xi\n",
    "            b -= n * error\n",
    "        \n",
    "\n",
    "    w = w * (y_std / x_std)\n",
    "    b = y_mean - w * x_mean\n",
    "    \n",
    "    return np.array([w, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sgd</th>\n",
       "      <td>1.617749</td>\n",
       "      <td>-180.855105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso</th>\n",
       "      <td>1.610230</td>\n",
       "      <td>-179.526286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              w           b\n",
       "sgd    1.617749 -180.855105\n",
       "lasso  1.610230 -179.526286"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "x = np.array([188, 181, 197, 168, 167, 187, 178, 194, 140, 176, 168, 192, 173, 142, 176]).reshape(-1, 1).reshape(15,1)\n",
    "y = np.array([141, 106, 149, 59, 79, 136, 65, 136, 52, 87, 115, 140, 82, 69, 121]).reshape(-1, 1).reshape(15,1)\n",
    "\n",
    "I = np.identity(2)\n",
    "alpha = 0.001\n",
    "\n",
    "sgd_result = sgd(x, y, alpha)\n",
    "sgd_result = sgd_result.ravel()\n",
    "\n",
    "x = np.asmatrix(np.c_[np.ones((15,1)),x])\n",
    "lasso_result = np.linalg.inv(x.T*x + alpha * I)*x.T*y\n",
    "lasso_result = lasso_result.ravel()\n",
    "\n",
    "prepared_results = np.asarray([sgd_result[0], sgd_result[1], lasso_result.item(1), lasso_result.item(0)])\n",
    "prepared_results = prepared_results.flatten()\n",
    "prepared_results = prepared_results.reshape(2, 2)\n",
    "\n",
    "final_result = pd.DataFrame(data=prepared_results, index=['sgd', 'lasso'], columns=[\"w\", \"b\"])\n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extend the Fisher's classifier\n",
    "\n",
    "Please extend the targets of the ``iris_data`` variable and use it as the $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92478522, 1.05141831],\n",
       "       [0.88521238, 1.03558917],\n",
       "       [0.90104152, 1.01976004],\n",
       "       [0.89312695, 1.01184547],\n",
       "       [0.93269979, 1.04350374],\n",
       "       [0.95644349, 1.07516201],\n",
       "       [0.91687065, 1.01184547],\n",
       "       [0.91687065, 1.04350374],\n",
       "       [0.87729781, 0.99601633],\n",
       "       [0.89312695, 1.03558917],\n",
       "       [0.94061436, 1.07516201],\n",
       "       [0.91687065, 1.02767461],\n",
       "       [0.88521238, 1.02767461],\n",
       "       [0.88521238, 0.98810177],\n",
       "       [0.96435806, 1.10682029],\n",
       "       [0.99601633, 1.09890572],\n",
       "       [0.95644349, 1.07516201],\n",
       "       [0.92478522, 1.05141831],\n",
       "       [0.94852893, 1.09890572],\n",
       "       [0.94852893, 1.05141831],\n",
       "       [0.91687065, 1.07516201],\n",
       "       [0.94061436, 1.05141831],\n",
       "       [0.93269979, 1.01184547],\n",
       "       [0.90895609, 1.05141831],\n",
       "       [0.91687065, 1.02767461],\n",
       "       [0.88521238, 1.04350374],\n",
       "       [0.91687065, 1.04350374],\n",
       "       [0.92478522, 1.05933288],\n",
       "       [0.91687065, 1.05933288],\n",
       "       [0.90104152, 1.01976004],\n",
       "       [0.89312695, 1.02767461],\n",
       "       [0.91687065, 1.07516201],\n",
       "       [0.97227263, 1.05933288],\n",
       "       [0.9801872 , 1.08307658],\n",
       "       [0.89312695, 1.03558917],\n",
       "       [0.90104152, 1.04350374],\n",
       "       [0.92478522, 1.08307658],\n",
       "       [0.93269979, 1.03558917],\n",
       "       [0.88521238, 0.99601633],\n",
       "       [0.91687065, 1.05141831],\n",
       "       [0.92478522, 1.04350374],\n",
       "       [0.82981041, 1.0039309 ],\n",
       "       [0.90104152, 0.99601633],\n",
       "       [0.92478522, 1.04350374],\n",
       "       [0.94852893, 1.05141831],\n",
       "       [0.88521238, 1.02767461],\n",
       "       [0.94852893, 1.05141831],\n",
       "       [0.90104152, 1.01184547],\n",
       "       [0.94061436, 1.06724745],\n",
       "       [0.90895609, 1.04350374],\n",
       "       [0.90104152, 1.2017951 ],\n",
       "       [0.90104152, 1.15430769],\n",
       "       [0.89312695, 1.19388053],\n",
       "       [0.82981041, 1.08307658],\n",
       "       [0.86938325, 1.16222226],\n",
       "       [0.86938325, 1.09890572],\n",
       "       [0.90895609, 1.14639313],\n",
       "       [0.83772498, 1.03558917],\n",
       "       [0.87729781, 1.17013683],\n",
       "       [0.86146868, 1.05933288],\n",
       "       [0.8060667 , 1.04350374],\n",
       "       [0.88521238, 1.11473485],\n",
       "       [0.82189584, 1.12264942],\n",
       "       [0.87729781, 1.13056399],\n",
       "       [0.87729781, 1.09099115],\n",
       "       [0.89312695, 1.1780514 ],\n",
       "       [0.88521238, 1.09099115],\n",
       "       [0.86146868, 1.10682029],\n",
       "       [0.82189584, 1.13847856],\n",
       "       [0.84563954, 1.09099115],\n",
       "       [0.90104152, 1.11473485],\n",
       "       [0.86938325, 1.13056399],\n",
       "       [0.84563954, 1.14639313],\n",
       "       [0.86938325, 1.13056399],\n",
       "       [0.87729781, 1.15430769],\n",
       "       [0.88521238, 1.17013683],\n",
       "       [0.86938325, 1.18596596],\n",
       "       [0.88521238, 1.1780514 ],\n",
       "       [0.87729781, 1.12264942],\n",
       "       [0.85355411, 1.09890572],\n",
       "       [0.83772498, 1.08307658],\n",
       "       [0.83772498, 1.08307658],\n",
       "       [0.86146868, 1.10682029],\n",
       "       [0.86146868, 1.12264942],\n",
       "       [0.88521238, 1.07516201],\n",
       "       [0.91687065, 1.12264942],\n",
       "       [0.89312695, 1.1780514 ],\n",
       "       [0.82981041, 1.14639313],\n",
       "       [0.88521238, 1.09099115],\n",
       "       [0.84563954, 1.08307658],\n",
       "       [0.85355411, 1.08307658],\n",
       "       [0.88521238, 1.13056399],\n",
       "       [0.85355411, 1.10682029],\n",
       "       [0.82981041, 1.04350374],\n",
       "       [0.86146868, 1.09099115],\n",
       "       [0.88521238, 1.09890572],\n",
       "       [0.87729781, 1.09890572],\n",
       "       [0.87729781, 1.13847856],\n",
       "       [0.84563954, 1.05141831],\n",
       "       [0.86938325, 1.09890572],\n",
       "       [0.90895609, 1.14639313],\n",
       "       [0.86146868, 1.10682029],\n",
       "       [0.88521238, 1.20970967],\n",
       "       [0.87729781, 1.14639313],\n",
       "       [0.88521238, 1.16222226],\n",
       "       [0.88521238, 1.24928251],\n",
       "       [0.84563954, 1.03558917],\n",
       "       [0.87729781, 1.2255388 ],\n",
       "       [0.84563954, 1.1780514 ],\n",
       "       [0.93269979, 1.21762424],\n",
       "       [0.90104152, 1.16222226],\n",
       "       [0.86146868, 1.15430769],\n",
       "       [0.88521238, 1.18596596],\n",
       "       [0.84563954, 1.09890572],\n",
       "       [0.86938325, 1.10682029],\n",
       "       [0.90104152, 1.15430769],\n",
       "       [0.88521238, 1.16222226],\n",
       "       [0.94852893, 1.25719708],\n",
       "       [0.85355411, 1.25719708],\n",
       "       [0.82189584, 1.12264942],\n",
       "       [0.90104152, 1.19388053],\n",
       "       [0.86938325, 1.09099115],\n",
       "       [0.86938325, 1.25719708],\n",
       "       [0.86146868, 1.14639313],\n",
       "       [0.90895609, 1.1780514 ],\n",
       "       [0.90104152, 1.21762424],\n",
       "       [0.86938325, 1.13847856],\n",
       "       [0.88521238, 1.13056399],\n",
       "       [0.86938325, 1.15430769],\n",
       "       [0.88521238, 1.21762424],\n",
       "       [0.86938325, 1.23345337],\n",
       "       [0.94852893, 1.27302621],\n",
       "       [0.86938325, 1.15430769],\n",
       "       [0.86938325, 1.14639313],\n",
       "       [0.85355411, 1.13056399],\n",
       "       [0.88521238, 1.25719708],\n",
       "       [0.91687065, 1.14639313],\n",
       "       [0.89312695, 1.15430769],\n",
       "       [0.88521238, 1.12264942],\n",
       "       [0.89312695, 1.19388053],\n",
       "       [0.89312695, 1.1780514 ],\n",
       "       [0.89312695, 1.19388053],\n",
       "       [0.86146868, 1.10682029],\n",
       "       [0.90104152, 1.18596596],\n",
       "       [0.90895609, 1.1780514 ],\n",
       "       [0.88521238, 1.1780514 ],\n",
       "       [0.84563954, 1.14639313],\n",
       "       [0.88521238, 1.16222226],\n",
       "       [0.91687065, 1.13847856],\n",
       "       [0.88521238, 1.11473485]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "iris_df = pd.DataFrame(iris_data.data,columns=iris_data.feature_names)\n",
    "iris_df.head()\n",
    "iris_df_target = pd.DataFrame(iris_data.target)\n",
    "\n",
    "x = iris_df[['sepal width (cm)','sepal length (cm)']].values\n",
    "y = iris_df_target.values\n",
    "dataset_size = np.size(x)\n",
    "\n",
    "mean_x, mean_y = np.mean(x), np.mean(y)\n",
    "\n",
    "SS_xy = np.sum(y * x) - dataset_size * mean_y * mean_x\n",
    "SS_xx = np.sum(x * x) - dataset_size * mean_x * mean_x\n",
    "\n",
    "a = SS_xy / SS_xx\n",
    "b = mean_y - a * mean_x\n",
    "\n",
    "\n",
    "y_pred = a * x + b\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
